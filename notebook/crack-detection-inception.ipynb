{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":792851,"sourceType":"datasetVersion","datasetId":414522}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-18T05:46:47.775434Z","iopub.execute_input":"2024-03-18T05:46:47.775805Z","iopub.status.idle":"2024-03-18T05:46:47.782082Z","shell.execute_reply.started":"2024-03-18T05:46:47.775769Z","shell.execute_reply":"2024-03-18T05:46:47.780982Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# pip install wandb -qU\n\n# import wandb\n# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:46:47.783511Z","iopub.execute_input":"2024-03-18T05:46:47.783770Z","iopub.status.idle":"2024-03-18T05:46:47.796553Z","shell.execute_reply.started":"2024-03-18T05:46:47.783736Z","shell.execute_reply":"2024-03-18T05:46:47.795582Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfrom torchvision import transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\nimport pandas as pd\n\nclass CrackDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n        # Define a mapping from string labels to integer labels\n        self.label_map = {'Positive': 1, 'Negative': 0}\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx, 0]\n        label_str = self.dataframe.iloc[idx, 1]\n\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n        \n        # Map string label to integer label\n        label_int = self.label_map[label_str]\n\n        # Convert label to tensor\n        label_tensor = torch.tensor(label_int, dtype=torch.long)\n\n        return image, label_tensor\n#         label = 0\n#         for i, c in enumerate(self.classes):\n#             if idx < len(os.listdir(os.path.join(self.data_dir, c))):\n#                 label = i\n#                 break\n                \n#             else:\n#                 idx -= len(os.listdir(os.path.join(self.data_dir, c)))\n                \n#             image_name = os.listdir(os.path.join(self.data_dir, self.classes[label]))[idx]\n#             image = Image.open(os.path.join(self.data_dir, self.classes[label], image_name))\n#             if self.transform:\n#                 image = self.transform(image)\n                \n#             return image, label","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:46:47.797943Z","iopub.execute_input":"2024-03-18T05:46:47.798198Z","iopub.status.idle":"2024-03-18T05:46:54.769817Z","shell.execute_reply.started":"2024-03-18T05:46:47.798177Z","shell.execute_reply":"2024-03-18T05:46:54.768963Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:46:54.770893Z","iopub.execute_input":"2024-03-18T05:46:54.771305Z","iopub.status.idle":"2024-03-18T05:47:08.054548Z","shell.execute_reply.started":"2024-03-18T05:46:54.771279Z","shell.execute_reply":"2024-03-18T05:47:08.053303Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.1)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.10.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom pytorch_lightning import LightningDataModule\n\nclass CrackDataModule(LightningDataModule):\n    def __init__(\n    self,\n    data_dir,\n    batch_size: int = 64,\n    num_workers: int = 0,\n    pin_memory: bool = False,\n    validation_split: float = 0.2,\n    shuffle_dataset: bool = True,\n    random_seed = 42,\n    ) -> None:\n        super().__init__()\n        self.data_dir = data_dir\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n        self.validation_split = validation_split\n        self.shuffle_dataset = shuffle_dataset\n        self.random_seed = random_seed\n        \n        self.transforms = transforms.Compose(\n            [\n                transforms.Resize((299, 299)),\n                transforms.ToTensor(),\n            ]\n        )\n        \n        self.batch_size = batch_size\n        \n    def prepare_data(self):\n        pass\n    \n    def setup(self, stage=None):\n#         self.data_dir = data_dir\n        all_files = []\n        labels = []\n        \n        for class_name in os.listdir(self.data_dir):\n            class_dir = os.path.join(self.data_dir, class_name)\n            for file in os.listdir(class_dir):\n                all_files.append(os.path.join(class_dir, file))\n                labels.append(class_name)\n                \n        train_files, val_files, train_labels, val_labels = train_test_split(\n            all_files, labels, test_size=self.validation_split, random_state=self.random_seed\n        )\n        \n        train_df = pd.DataFrame({'file_path': train_files, 'label': train_labels})\n        val_df = pd.DataFrame({'file_path': val_files, 'label': val_labels})\n        \n        self.train_dataset = CrackDataset(dataframe=train_df, transform=self.transforms)\n        self.val_dataset = CrackDataset(dataframe=val_df, transform=self.transforms)     \n        \n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=self.shuffle_dataset\n        )\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False\n        )\n    \n    def test_dataloader(self):\n        pass","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:47:08.056982Z","iopub.execute_input":"2024-03-18T05:47:08.057300Z","iopub.status.idle":"2024-03-18T05:47:10.995737Z","shell.execute_reply.started":"2024-03-18T05:47:08.057273Z","shell.execute_reply":"2024-03-18T05:47:10.994933Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchmetrics import Accuracy\n\nclass InceptionCustom(nn.Module):\n    def __init__(\n        self,\n        num_classes\n    ) -> None:\n        super(InceptionCustom, self).__init__()\n        self.model =  torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n        num_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_features, num_classes)\n        \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:47:10.997059Z","iopub.execute_input":"2024-03-18T05:47:10.997441Z","iopub.status.idle":"2024-03-18T05:47:11.004738Z","shell.execute_reply.started":"2024-03-18T05:47:10.997408Z","shell.execute_reply":"2024-03-18T05:47:11.003533Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning import LightningModule\nimport torch.nn.functional as F\nimport torchmetrics\n\nclass Classifier(LightningModule):\n    def __init__(\n        self,\n        net: torch.nn.Module,\n        lr: float = 0.001\n    ) -> None:\n        super().__init__()\n        self.model = net\n        self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n        self.lr = lr\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.model(x)\n    \n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self.model(inputs)\n        # No need to apply softmax here, as it's likely already applied in the model\n        loss = F.cross_entropy(outputs.logits, labels)\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self.model(inputs)\n        # No need to apply softmax here, as it's likely already applied in the model\n        loss = F.cross_entropy(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        acc = self.accuracy(preds, labels)\n        self.log(\"val_loss\", loss, prog_bar=True)\n        self.log(\"val_acc\", acc, prog_bar=True)\n\n\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:49:33.403916Z","iopub.execute_input":"2024-03-18T05:49:33.404673Z","iopub.status.idle":"2024-03-18T05:49:33.415185Z","shell.execute_reply.started":"2024-03-18T05:49:33.404640Z","shell.execute_reply":"2024-03-18T05:49:33.414240Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split\n\n# Inisialisasi CrackDataModule\ndata_module = CrackDataModule(data_dir=\"/kaggle/input/surface-crack-detection\", batch_size=64)\n\n# Inisialisasi model InceptionV3\nnum_classes = 2\ninception_model = InceptionCustom(num_classes=num_classes)\n\n# Inisialisasi Classifier\nclassifier = Classifier(net=inception_model, lr=0.001)\n\n# Inisialisasi PyTorch Lightning Trainer\ntrainer = pl.Trainer(max_epochs=10)  \n\n# Melatih model\ntrainer.fit(classifier, data_module)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T05:49:37.533320Z","iopub.execute_input":"2024-03-18T05:49:37.533703Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|██████████| 104M/104M [00:00<00:00, 151MB/s]  \n2024-03-18 05:49:43.743016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-18 05:49:43.743142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-18 05:49:43.865209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d037911ed794535b50498c4174fc1ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]}]}